{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking_GPU_Availabilty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1650'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.current_device()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMD Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorboard --logdir=\"C:\\Users\\User\\OneDrive - University College London\\UCL Education\\Year 4\\MLS\\Coursework\\AMLS_assignment24_25\\Task A\\runs\\DisplayImage\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library imports, data loading and visualisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import medmnist\n",
    "from medmnist import BreastMNIST\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import os\n",
    "from tensorboard import program\n",
    "\n",
    "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
    "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
    "from tqdm import tqdm  # For nice progress bar!\n",
    "import torchvision.datasets as datasets  # Standard datasets\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading datatsets from BreastMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomAdjustSharpness(sharpness_factor=2,p=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    # transforms.RandomAdjustSharpness(p=1,sharpness_factor=1.1),\n",
    "    # transforms.RandomEqualize(p=0.3),\n",
    "    # transforms.RandomVerticalFlip(p=0.1),\n",
    "    # transforms.RandomHorizontalFlip(p=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize((0.5,), (0.5,))  # Mean and standard deviation for grayscale images\n",
    "])\n",
    "#Cannot blindly augment the data to what we want\n",
    "#the classifiers depend on the chape of the tumer hence all the below is good\n",
    "#Might consider increaasing the contrast and brightness to allow easier identificationn\n",
    "#CANCEL contrast... USE histogram equaliser instetad\n",
    "transforms.RandomVerticalFlip()\n",
    "transforms.RandomHorizontalFlip()\n",
    "transforms.RandomRotation(degrees=180)\n",
    "transforms.RandomEqualize(p=1)\n",
    "transforms.RandomAdjustSharpness(p=1,sharpness_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "#loading train,val,test into variables\n",
    "train_data=medmnist.BreastMNIST(split=\"train\",transform=transform)\n",
    "val_data=medmnist.BreastMNIST(split=\"val\",transform=transforms.ToTensor())\n",
    "test_data=medmnist.BreastMNIST(split=\"test\",transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation and class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before oversampling: Counter({1: 399, 0: 147})\n",
      "Batch 1 class distribution: Counter({0: 17, 1: 15})\n",
      "Batch 2 class distribution: Counter({0: 17, 1: 15})\n",
      "Batch 3 class distribution: Counter({0: 19, 1: 13})\n",
      "Total class distribution in the dataloader: Counter({1: 299, 0: 247})\n",
      "576\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the dataset\n",
    "dataset = medmnist.BreastMNIST(split=\"train\",transform=transform)\n",
    "\n",
    "# Count class occurrences\n",
    "class_counts = Counter(dataset.labels.reshape(-1))\n",
    "print(f\"Class distribution before oversampling: {class_counts}\")\n",
    "\n",
    "# Compute sample weights: Inverse of class frequencies\n",
    "class_weights = 1.0 / torch.tensor([class_counts[cls] for cls in sorted(class_counts.keys())], dtype=torch.float)\n",
    "sample_weights = torch.tensor([class_weights[label] for label in dataset.labels.reshape(-1)], dtype=torch.float)\n",
    "\n",
    "# Create WeightedRandomSampler\n",
    "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "# Create DataLoader with sampler\n",
    "dataloader = DataLoader(dataset, batch_size=32, sampler=sampler)\n",
    "train_data=dataloader\n",
    "# Check the distribution of classes in a few batches\n",
    "for batch_idx, (data, labels) in enumerate(dataloader):\n",
    "    print(f\"Batch {batch_idx+1} class distribution: {Counter(labels.reshape(-1).tolist())}\")\n",
    "    if batch_idx == 2:  # Check only the first 3 batches\n",
    "        break\n",
    "\n",
    "# Initialize a Counter for tracking class counts\n",
    "total_class_counts = Counter()\n",
    "\n",
    "# Iterate through the entire dataloader\n",
    "for data, labels in dataloader:\n",
    "    # Flatten the labels and convert them to a list\n",
    "    total_class_counts.update(labels.reshape(-1).tolist())\n",
    "\n",
    "# Print the total distribution of classes\n",
    "print(f\"Total class distribution in the dataloader: {total_class_counts}\")\n",
    "print(len(dataloader)*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({1: 52, 0: 12})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, labels=next(iter(train_loader))\n",
    "x=labels.view(-1)\n",
    "x=x.tolist()\n",
    "print(x)\n",
    "Counter(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Example mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = 784\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 5\n",
    "\n",
    "# Load Data\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([32, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(train_data)\n",
    "# print(\"=====================\")\n",
    "# print(val_data)\n",
    "# print(\"=====================\")\n",
    "# print(test_data)\n",
    "\n",
    "for i, (images, labels) in enumerate(train_loader):\n",
    "    print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399\n",
      "147\n"
     ]
    }
   ],
   "source": [
    "#visualising the size of the image and its labels\n",
    "one=0\n",
    "zero=0\n",
    "for image , label in train_data:\n",
    "    # print(image.shape)\n",
    "    # print(label)\n",
    "    if label==0:\n",
    "        zero+=1\n",
    "    else:\n",
    "        one+=1\n",
    "print(one)\n",
    "print(zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying images on Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location of tensorboard folder\n",
    "folder=\"runs/DisplayImage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to delete runs/DisplayImage\\Epoch_Epoch Accuracy_Test: [WinError 5] Access is denied: 'runs/DisplayImage\\\\Epoch_Epoch Accuracy_Test'\n",
      "Failed to delete runs/DisplayImage\\Epoch_Epoch Accuracy_Train: [WinError 5] Access is denied: 'runs/DisplayImage\\\\Epoch_Epoch Accuracy_Train'\n",
      "Failed to delete runs/DisplayImage\\Epoch_Epoch loss_Test: [WinError 5] Access is denied: 'runs/DisplayImage\\\\Epoch_Epoch loss_Test'\n",
      "Failed to delete runs/DisplayImage\\Epoch_Epoch loss_Train: [WinError 5] Access is denied: 'runs/DisplayImage\\\\Epoch_Epoch loss_Train'\n",
      "Deleted: runs/DisplayImage\\events.out.tfevents.1733867044.DESKTOP-3FC1MTH.29016.68\n",
      "All contents of the folder 'runs/DisplayImage' have been cleared.\n"
     ]
    }
   ],
   "source": [
    "clear_folder(folder)\n",
    "#show using dataset on tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\n",
    "writer = SummaryWriter(f\"runs/DisplayImage\")\n",
    "for index in range(100):\n",
    "    data,label=train_data[index]\n",
    "    writer.add_image(\"mnist_images\", data,index)\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to delete runs/DisplayImage\\Epoch_Epoch Accuracy_Test: [WinError 5] Access is denied: 'runs/DisplayImage\\\\Epoch_Epoch Accuracy_Test'\n",
      "Failed to delete runs/DisplayImage\\Epoch_Epoch Accuracy_Train: [WinError 5] Access is denied: 'runs/DisplayImage\\\\Epoch_Epoch Accuracy_Train'\n",
      "Failed to delete runs/DisplayImage\\Epoch_Epoch loss_Test: [WinError 5] Access is denied: 'runs/DisplayImage\\\\Epoch_Epoch loss_Test'\n",
      "Failed to delete runs/DisplayImage\\Epoch_Epoch loss_Train: [WinError 5] Access is denied: 'runs/DisplayImage\\\\Epoch_Epoch loss_Train'\n",
      "Deleted: runs/DisplayImage\\events.out.tfevents.1733866663.DESKTOP-3FC1MTH.29016.63\n",
      "All contents of the folder 'runs/DisplayImage' have been cleared.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method SummaryWriter.close of <torch.utils.tensorboard.writer.SummaryWriter object at 0x0000022A861F86A0>>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_folder(folder)\n",
    "#show using dataloader with batches\n",
    "for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "    # create grid of images\n",
    "    img_grid = torchvision.utils.make_grid(data)\n",
    "    # write to tensorboard\n",
    "    writer.add_image(f\"MNIST Example - image batch \", img_grid,batch_idx)\n",
    "    #print(batch_idx)\n",
    "writer.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img,label = train_data[1]\n",
    "image_np = img.squeeze()\n",
    "print(image_np.shape)\n",
    "# Plot the image\n",
    "plt.imshow(image_np,cmap=\"gray\")\n",
    "plt.axis('off')  # Hide the axes for better visualization\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1650'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device cuda for GPU if it's available otherwise run on the CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to copy tensor files save\n",
    "def copy_directory(source_dir, destination_dir):\n",
    "    \"\"\"\n",
    "    Copies all files and folders from a source directory to a destination directory.\n",
    "\n",
    "    Args:\n",
    "        source_dir (str): The path to the source directory.\n",
    "        destination_dir (str): The path to the existing destination directory.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure the destination directory exists\n",
    "        if not os.path.isdir(destination_dir):\n",
    "            print(f\"Error: Destination directory '{destination_dir}' does not exist.\")\n",
    "            return\n",
    "\n",
    "        # Copy the content of source dir to destination directory\n",
    "        shutil.copytree(source_dir, os.path.join(destination_dir, os.path.basename(source_dir)))\n",
    "        print(f\"Successfully copied the content of '{source_dir}' to '{destination_dir}'\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Source directory '{source_dir}' not found.\")\n",
    "    except shutil.Error as e:\n",
    "        print(f\"Error during copy: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "#function to clear tensorboard files\n",
    "\n",
    "def clear_folder(folder_path):\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"The folder '{folder_path}' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    # Iterate through all items in the folder\n",
    "    for item in os.listdir(folder_path):\n",
    "        item_path = os.path.join(folder_path, item)\n",
    "        try:\n",
    "            # Remove directories\n",
    "            if os.path.isdir(item_path):\n",
    "                shutil.rmtree(item_path)\n",
    "            # Remove files\n",
    "            else:\n",
    "                os.remove(item_path)\n",
    "            print(f\"Deleted: {item_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {item_path}: {e}\")\n",
    "    \n",
    "    print(f\"All contents of the folder '{folder_path}' have been cleared.\")\n",
    "    #location of tensorboard folder\n",
    "folder=\"runs/DisplayImage\"\n",
    "\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        \"\"\"\n",
    "        Here we define the layers of the network. We create two fully connected layers\n",
    "\n",
    "        Parameters:\n",
    "            input_size: the size of the input, in this case 784 (28x28)\n",
    "            num_classes: the number of classes we want to predict, in this case 2 (0-1)\n",
    "\n",
    "        \"\"\"\n",
    "        super(NN, self).__init__()\n",
    "        # # Our first linear layer take input_size, in this case 784 nodes to 50\n",
    "        # # and our second linear layer takes 50 to the num_classes we have, in\n",
    "        # # this case 10.\n",
    "        # self.fc1 = nn.Linear(input_size, 50)\n",
    "        # self.fc2 = nn.Linear(50, num_classes)\n",
    "\n",
    "        self.flatten = nn.Flatten() #flattens the input tensors\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 2),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(512, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x here is the mnist images and we run it through the network that we created above.\n",
    "        Parameters:\n",
    "            x: mnist images\n",
    "        Returns:\n",
    "            out: the output of the network\n",
    "        \"\"\"\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=2):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(  #same convolution\n",
    "            in_channels=in_channels,\n",
    "            out_channels=8,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=8,\n",
    "            out_channels=16, \n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.fc1 = nn.Linear(16 * 7 * 7, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "class NN2(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        \"\"\"\n",
    "        Here we define the layers of the network. We create two fully connected layers\n",
    "\n",
    "        Parameters:\n",
    "            input_size: the size of the input, in this case 784 (28x28)\n",
    "            num_classes: the number of classes we want to predict, in this case 10 (0-9)\n",
    "\n",
    "        \"\"\"\n",
    "        super(NN2, self).__init__()\n",
    "        # Our first linear layer take input_size, in this case 784 nodes to 50\n",
    "        # and our second linear layer takes 50 to the num_classes we have, in\n",
    "        # this case 10.\n",
    "        self.flatten = nn.Flatten() #flattens the input tensors\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x here is the mnist images and we run it through fc1, fc2 that we created above.\n",
    "        we also add a ReLU activation function in between and for that (since it has no parameters)\n",
    "        I recommend using nn.functional (F)\n",
    "\n",
    "        Parameters:\n",
    "            x: mnist images\n",
    "\n",
    "        Returns:\n",
    "            out: the output of the network\n",
    "        \"\"\"\n",
    "        x=self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    accuracies=[]\n",
    "    batch_loss=0\n",
    "    for batch, (input_data, class_cat) in enumerate(tqdm(dataloader)):\n",
    "        input_data, class_cat = input_data.to(device), class_cat.to(device)\n",
    "\n",
    "        ## Compute prediction error\n",
    "        pred = model(input_data)\n",
    "        class_cat=class_cat.squeeze().long()\n",
    "        loss = loss_fn(pred, class_cat)\n",
    "\n",
    "        ## Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        ## calculation running loss\n",
    "        loss, current = loss.item(), (batch + 1) * len(input_data)\n",
    "\n",
    "\n",
    "        ##caculating running accuracy\n",
    "        _, predictions = pred.max(1)\n",
    "        num_correct = (predictions == class_cat).sum()\n",
    "        running_train_acc = float(num_correct) / float(input_data.shape[0])\n",
    "        # print(\"model Output>>>>>\")\n",
    "        # print(pred)\n",
    "        # print(\"predictions>>>\")\n",
    "        # print(predictions)\n",
    "        # print(\"num_correct>>>>>\")\n",
    "        # print(num_correct)\n",
    "        # print(\"accuracy>>>>\")\n",
    "        # print(running_train_acc)\n",
    "        # print(data.shape[0])\n",
    "        # print(input_data.shape[0])\n",
    "        accuracies.append(running_train_acc)\n",
    "\n",
    "        ##Plot stuff to tensorboard tensorboard\n",
    "        global step\n",
    "        writer.add_scalar(\"Batch/Training loss\",loss,global_step=step)\n",
    "        writer.add_scalar(\"Batch/Training Accuracy\", running_train_acc, global_step=step)\n",
    "        # global batch_loss\n",
    "        # batch_loss.append(loss)\n",
    "        batch_loss+=loss\n",
    "\n",
    "        \n",
    "        step += 1\n",
    "\n",
    "\n",
    "        #print(f\"loss: {loss:>7f} accuracy: {running_train_acc:>5f}  [{current:>5d}/{size:>5d}]\")\n",
    "    \n",
    "    ## Calculate epoch accuracy\n",
    "    epoch_accuracy=sum(accuracies)/len(accuracies)\n",
    "\n",
    "    ## Getting the average epoch loss\n",
    "    epoch_loss=batch_loss/size\n",
    "    \n",
    "    ## Send it to tensorboard\n",
    "    writer.add_scalars(\"Epoch/Epoch loss\",{'Train':epoch_loss},global_step=epoch)\n",
    "    writer.add_scalars(\"Epoch/Epoch Accuracy\",{\"Train\":epoch_accuracy},global_step=epoch)\n",
    "    \n",
    "def val(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y=y.squeeze().long()\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    writer.add_scalars(\"Epoch/Epoch loss\",{'Test':test_loss},global_step=epoch)\n",
    "    writer.add_scalars(\"Epoch/Epoch Accuracy\",{\"Test\":correct},global_step=epoch)\n",
    "    print(f\"val Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "\n",
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y = y.squeeze().long()\n",
    "            pred = model(X)\n",
    "            # Collect predictions and true labels\n",
    "            all_labels.append(int(y))\n",
    "            all_predictions.append(int(pred.argmax(1)))\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    correct /= size\n",
    "\n",
    "    # Build confusion matrix\n",
    "    conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "    class_names = [\"False\", \"Positive\"]  # Update as needed for your use case\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.tight_layout()  # Ensure labels fit within figure boundaries\n",
    "    \n",
    "\n",
    "    # Convert plot to image\n",
    "    fig = plt.gcf()\n",
    "    fig.canvas.draw()\n",
    "    width, height = fig.canvas.get_width_height()\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8').reshape(height, width, 3)\n",
    "    plt.show()\n",
    "    plt.close(fig)  # Close figure to free memory\n",
    "\n",
    "    # Log image to \n",
    "    writer.add_image(\"Confusion Matrix\", np.transpose(image, (2, 0, 1)),global_step=1)\n",
    " \n",
    "    # Log accuracy to TensorBoard\n",
    "    writer.add_scalar(\"Test Accuracy\", correct,global_step=1)\n",
    "\n",
    "    # Print accuracy\n",
    "    print(f\"Test Error: \\n Accuracy: {(100 * correct):>0.1f}%\\n\")\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "def savemodel(model_name,model,tensor_path):\n",
    "    try:\n",
    "        os.mkdir(\"only_one_folder\") # Will not create parent folders, unlike os.makedirs()\n",
    "        print(f\"Folder created successfully\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error creating folder: {e}\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 10])\n",
      "torch.Size([20, 10])\n"
     ]
    }
   ],
   "source": [
    "#basinc testing for the model\n",
    "model=CNN()\n",
    "x=torch.randn(20,1,28,28)\n",
    "print(model(x).shape)\n",
    "\n",
    "model=NN(input_size=28*28,num_classes=2)\n",
    "x=torch.randn(20,1,28,28)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully connected network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#batch_size = 64 Note: this was determined when we loaded the data previously\u001b[39;00m\n\u001b[0;32m      6\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mNN\u001b[49m(input_size\u001b[38;5;241m=\u001b[39minput_size, num_classes\u001b[38;5;241m=\u001b[39mnum_classes)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m## Setting up training and test function\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'NN' is not defined"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "input_size = 28*28\n",
    "num_classes = 2\n",
    "learning_rate = 0.001\n",
    "#batch_size = 64 Note: this was determined when we loaded the data previously\n",
    "num_epochs = 100\n",
    "\n",
    "model = NN(input_size=input_size, num_classes=num_classes).to(device)\n",
    "print(model)\n",
    "## Setting up training and test function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "##clear tensorboard folder\n",
    "clear_folder(folder)\n",
    "writer = SummaryWriter(f\"runs/DisplayImage\")\n",
    "\n",
    "#show using dataset on tensorboard\n",
    "for index, (data,label) in enumerate(train_loader):\n",
    "    data,label=train_data[index]\n",
    "    writer.add_image(\"mnist_images\", data,index)\n",
    "\n",
    "# Visualize model in TensorBoard\n",
    "example_img, labels = next(iter(train_loader))\n",
    "#example_img=example_img[0]\n",
    "writer.add_graph(model,example_img.to(device))\n",
    "print(\"Model sent to tensorboard\")\n",
    "\n",
    "step=0\n",
    "# epoch_loss=[]\n",
    "for t in range(num_epochs):\n",
    "    epoch=t\n",
    "    # batch_loss=[]\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    \n",
    "    # epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
    "    # writer.add_scalar(\"Epoch Training loss\",epoch_loss[t],global_step=t)\n",
    "    val(val_loader, model, loss_fn)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=784, out_features=2, bias=True)\n",
      ")\n",
      "Failed to delete runs/DisplayImage\\Epoch_Epoch Accuracy_Test: [WinError 5] Access is denied: 'runs/DisplayImage\\\\Epoch_Epoch Accuracy_Test'\n",
      "Failed to delete runs/DisplayImage\\Epoch_Epoch Accuracy_Train: [WinError 5] Access is denied: 'runs/DisplayImage\\\\Epoch_Epoch Accuracy_Train'\n",
      "Failed to delete runs/DisplayImage\\Epoch_Epoch loss_Test: [WinError 5] Access is denied: 'runs/DisplayImage\\\\Epoch_Epoch loss_Test'\n",
      "Failed to delete runs/DisplayImage\\Epoch_Epoch loss_Train: [WinError 5] Access is denied: 'runs/DisplayImage\\\\Epoch_Epoch loss_Train'\n",
      "Deleted: runs/DisplayImage\\events.out.tfevents.1733980011.DESKTOP-3FC1MTH.3756.27\n",
      "All contents of the folder 'runs/DisplayImage' have been cleared.\n",
      "Model sent to tensorboard\n",
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 59.69it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (1) to match target batch_size (0).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[111], line 41\u001b[0m\n\u001b[0;32m     37\u001b[0m     train(train_loader, model, loss_fn, optimizer)\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# epoch_loss.append(sum(batch_loss)/len(batch_loss))\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# writer.add_scalar(\"Epoch Training loss\",epoch_loss[t],global_step=t)\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     \u001b[43mval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[101], line 232\u001b[0m, in \u001b[0;36mval\u001b[1;34m(dataloader, model, loss_fn)\u001b[0m\n\u001b[0;32m    230\u001b[0m         y\u001b[38;5;241m=\u001b[39my\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mlong()\n\u001b[0;32m    231\u001b[0m         pred \u001b[38;5;241m=\u001b[39m model(X)\n\u001b[1;32m--> 232\u001b[0m         test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    233\u001b[0m         correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (pred\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m y)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    234\u001b[0m test_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m num_batches\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\MLS_CW\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\MLS_CW\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\MLS_CW\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1293\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\MLS_CW\\lib\\site-packages\\torch\\nn\\functional.py:3479\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3478\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3483\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3486\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (1) to match target batch_size (0)."
     ]
    }
   ],
   "source": [
    "# Full implementation\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 28*28\n",
    "num_classes = 2\n",
    "learning_rate = 0.005\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "\n",
    "model = CNN().to(device)\n",
    "print(model)\n",
    "## Setting up training and test function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "##clear tensorboard folder\n",
    "clear_folder(folder)\n",
    "writer = SummaryWriter(f\"runs/DisplayImage\")\n",
    "\n",
    "#show using dataset on tensorboard\n",
    "# for index, (data,label) in enumerate(train_loader):\n",
    "#     data,label=train_data[index]\n",
    "#     writer.add_image(\"mnist_images\", data,index)\n",
    "\n",
    "# Visualize model in TensorBoard\n",
    "example_img, labels = next(iter(train_loader))\n",
    "#example_img=example_img[0]\n",
    "writer.add_graph(model,example_img.to(device))\n",
    "print(\"Model sent to tensorboard\")\n",
    "\n",
    "step=0\n",
    "# epoch_loss=[]\n",
    "for t in range(num_epochs):\n",
    "    epoch=t\n",
    "    # batch_loss=[]\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(val_loader, model, loss_fn, optimizer)\n",
    "    \n",
    "    # epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
    "    # writer.add_scalar(\"Epoch Training loss\",epoch_loss[t],global_step=t)\n",
    "    val(test_loader, model, loss_fn)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\User/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "c:\\Users\\User\\anaconda3\\envs\\MLS_CW\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\envs\\MLS_CW\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): Identity()\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Failed to delete runs/DisplayImage\\Epoch_Epoch Accuracy_Test: [WinError 5] Access is denied: 'runs/DisplayImage\\\\Epoch_Epoch Accuracy_Test'\n",
      "Failed to delete runs/DisplayImage\\Epoch_Epoch Accuracy_Train: [WinError 5] Access is denied: 'runs/DisplayImage\\\\Epoch_Epoch Accuracy_Train'\n",
      "Failed to delete runs/DisplayImage\\Epoch_Epoch loss_Test: [WinError 5] Access is denied: 'runs/DisplayImage\\\\Epoch_Epoch loss_Test'\n",
      "Failed to delete runs/DisplayImage\\Epoch_Epoch loss_Train: [WinError 5] Access is denied: 'runs/DisplayImage\\\\Epoch_Epoch loss_Train'\n",
      "Deleted: runs/DisplayImage\\events.out.tfevents.1734023082.DESKTOP-3FC1MTH.15284.0\n",
      "All contents of the folder 'runs/DisplayImage' have been cleared.\n",
      "Model sent to tensorboard\n",
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 16.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 26.9%, Avg loss: 0.723362 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.574957 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.556036 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.711373 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 64.1%, Avg loss: 0.592650 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 35.9%, Avg loss: 1.886210 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.666806 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.611235 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.373534 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.337879 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.688217 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 83.3%, Avg loss: 1.552505 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.540679 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.282587 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.595237 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.430761 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.659118 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.419682 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.380097 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.821144 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 84.6%, Avg loss: 1.006874 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.948122 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.458263 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.299074 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.784125 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 25.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.317195 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.561128 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.213093 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 23.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.462488 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.361690 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.331233 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.361257 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.374547 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 82.1%, Avg loss: 1.111761 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.663307 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.418466 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.605142 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.564032 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.616405 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.324511 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.558949 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.775034 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 94.9%, Avg loss: 0.400854 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.270467 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.458827 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.396888 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.292720 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.297837 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.337658 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.529217 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.361664 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.269620 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.468912 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.976231 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.943861 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 25.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.400384 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.967712 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 23.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.482815 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.275890 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.513577 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.447479 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.374258 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.387306 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.819682 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 23.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.325743 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.415219 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.384711 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 87.2%, Avg loss: 1.043435 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.635756 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 23.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.714629 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.391365 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.303549 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.692130 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.403261 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.684839 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.667662 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.589311 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.793811 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.409407 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 78.2%, Avg loss: 1.918406 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.294673 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.578024 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.781829 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 23.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 82.1%, Avg loss: 1.472114 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.647712 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.633448 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.940034 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.448717 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.639024 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.861204 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.458353 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.691777 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.848007 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.858434 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 87.2%, Avg loss: 1.032709 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 93.6%, Avg loss: 0.275886 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 23.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 93.6%, Avg loss: 0.443593 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 25.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.799950 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.702883 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 24.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.514377 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 85.9%\n",
      "\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_15284\\2339920838.py:279: MatplotlibDeprecationWarning: The tostring_rgb function was deprecated in Matplotlib 3.8 and will be removed in 3.10. Use buffer_rgba instead.\n",
      "  image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8').reshape(height, width, 3)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    # transforms.RandomAdjustSharpness(p=1,sharpness_factor=1.1),\n",
    "    # transforms.RandomEqualize(p=0.3),\n",
    "    # transforms.RandomVerticalFlip(p=0.1),\n",
    "    # transforms.RandomHorizontalFlip(p=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize((0.5,), (0.5,))  # Mean and standard deviation for grayscale images\n",
    "])\n",
    "\n",
    "batch_size=64\n",
    "#loading train,val,test into variables\n",
    "train_data=medmnist.BreastMNIST(split=\"train\",transform=transform)\n",
    "val_data=medmnist.BreastMNIST(split=\"val\",transform=transforms.ToTensor())\n",
    "test_data=medmnist.BreastMNIST(split=\"test\",transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 28*28\n",
    "num_classes = 2\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "\n",
    "#Freeze the model\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad=False\n",
    "\n",
    "model.conv1 = nn.Conv2d(\n",
    "    in_channels=1,  # Change to 1 channel for grayscale\n",
    "    out_channels=64,\n",
    "    kernel_size=(7, 7),\n",
    "    stride=(2, 2),\n",
    "    padding=(3, 3),\n",
    "    bias=False\n",
    ")\n",
    "\n",
    "# Optionally copy pretrained weights and average across RGB channels\n",
    "with torch.no_grad():\n",
    "    pretrained_weights = model.conv1.weight  # Original weights for RGB\n",
    "    model.conv1.weight.copy_(torch.mean(pretrained_weights, dim=1, keepdim=True))\n",
    "\n",
    "# Adjust the fully connected layer to match the number of output classes\n",
    "num_classes = 2  # Example: MNIST has 10 classes\n",
    "model.fc = nn.Sequential(\n",
    "            nn.Linear(512, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 2),\n",
    ")\n",
    "model.avgpool = nn.Identity()\n",
    "\n",
    "print(model)\n",
    "\n",
    "## Setting up training and test function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Move model to the correct device\n",
    "model = model.to(device)\n",
    "\n",
    "##clear tensorboard folder\n",
    "clear_folder(folder)\n",
    "writer = SummaryWriter(f\"runs/DisplayImage\")\n",
    "\n",
    "#show using dataset on tensorboard\n",
    "for index, (data,label) in enumerate(train_loader):\n",
    "    data,label=train_data[index]\n",
    "    writer.add_image(\"mnist_images\", data,index)\n",
    "\n",
    "# Visualize model in TensorBoard\n",
    "example_img, labels = next(iter(train_loader))\n",
    "#example_img=example_img[0]\n",
    "writer.add_graph(model,example_img.to(device))\n",
    "print(\"Model sent to tensorboard\")\n",
    "\n",
    "\n",
    "step=0\n",
    "# epoch_loss=[]\n",
    "for t in range(num_epochs):\n",
    "    epoch=t\n",
    "    # batch_loss=[]\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    \n",
    "    # epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
    "    # writer.add_scalar(\"Epoch Training loss\",epoch_loss[t],global_step=t)\n",
    "    val(val_loader, model, loss_fn)\n",
    "\n",
    "test(test_loader,model)\n",
    "writer.close()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save current model with results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating folder: [WinError 183] Cannot create a file when that file already exists: 'Saved_models/R18_E&E'\n",
      "An unexpected error occurred: [WinError 183] Cannot create a file when that file already exists: 'Saved_models/R18_E&E\\\\DisplayImage'\n",
      "Entire model saved to: Saved_models/R18_E&E/R18_E&E.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "modelname=\"R18_E&E\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(f\"Saved_models/{modelname}\") # Will not create parent folders, unlike os.makedirs()\n",
    "    print(f\"Folder created successfully\")\n",
    "except OSError as e:\n",
    "    print(f\"Error creating folder: {e}\")    \n",
    "tensorpath=\"runs\\DisplayImage\"\n",
    "copy_directory(tensorpath,f\"Saved_models/{modelname}\")\n",
    "\n",
    "# 7. Save entire model (Less recommended).\n",
    "save_entire_model_path = f\"Saved_models/{modelname}/{modelname}.pth\"\n",
    "torch.save(model, save_entire_model_path)\n",
    "print(f\"Entire model saved to: {save_entire_model_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entire model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3756\\150428221.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_entire_model = torch.load(f\"Saved_models/{modelname}/simple_model_entire.pth\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 8. Load entire model\n",
    "loaded_entire_model = torch.load(f\"Saved_models/{modelname}/simple_model_entire.pth\")\n",
    "loaded_entire_model = loaded_entire_model.to(device)\n",
    "loaded_entire_model.eval()\n",
    "print(\"Entire model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'Alex' created successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Specify the folder name\n",
    "folder_name = \"Alex\"\n",
    "\n",
    "# Create the folder\n",
    "try:\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "    print(f\"Folder '{folder_name}' created successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while creating the folder: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'Alex' and its contents deleted successfully!\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Specify the folder to delete\n",
    "folder_name = \"Alex\"\n",
    "\n",
    "# Delete the folder and its contents\n",
    "try:\n",
    "    shutil.rmtree(folder_name)  # Removes the folder and all its contents\n",
    "    print(f\"Folder '{folder_name}' and its contents deleted successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Folder '{folder_name}' does not exist.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'Alex/name' is not empty. Cannot delete it using os.rmdir.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Specify the folder to delete\n",
    "folder_name = \"Alex/name\"\n",
    "\n",
    "# Delete the folder\n",
    "try:\n",
    "    os.rmdir(folder_name)  # Removes only empty folders\n",
    "    print(f\"Folder '{folder_name}' deleted successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Folder '{folder_name}' does not exist.\")\n",
    "except OSError:\n",
    "    print(f\"Folder '{folder_name}' is not empty. Cannot delete it using os.rmdir.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLS_CW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
