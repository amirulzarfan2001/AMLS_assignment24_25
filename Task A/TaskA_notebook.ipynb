{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking_GPU_Availabilty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1650'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.current_device()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMD Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorboard --logdir=\"C:\\Users\\User\\OneDrive - University College London\\UCL Education\\Year 4\\MLS\\Coursework\\AMLS_assignment24_25\\Task A\\runs\\DisplayImage\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library imports, data loading and visualisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import medmnist\n",
    "from medmnist import BreastMNIST\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import os\n",
    "from tensorboard import program\n",
    "\n",
    "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
    "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
    "from tqdm import tqdm  # For nice progress bar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clear tensorboard files\n",
    "\n",
    "def clear_folder(folder_path):\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"The folder '{folder_path}' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    # Iterate through all items in the folder\n",
    "    for item in os.listdir(folder_path):\n",
    "        item_path = os.path.join(folder_path, item)\n",
    "        try:\n",
    "            # Remove directories\n",
    "            if os.path.isdir(item_path):\n",
    "                shutil.rmtree(item_path)\n",
    "            # Remove files\n",
    "            else:\n",
    "                os.remove(item_path)\n",
    "            print(f\"Deleted: {item_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {item_path}: {e}\")\n",
    "    \n",
    "    print(f\"All contents of the folder '{folder_path}' have been cleared.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading datatsets from BreastMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Mean and standard deviation for grayscale images\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=20\n",
    "#loading train,val,test into variables\n",
    "train_data=medmnist.BreastMNIST(split=\"train\",transform=transforms.ToTensor())\n",
    "val_data=medmnist.BreastMNIST(split=\"val\",transform=transforms.ToTensor())\n",
    "test_data=medmnist.BreastMNIST(split=\"test\",transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([6, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(train_data)\n",
    "# print(\"=====================\")\n",
    "# print(val_data)\n",
    "# print(\"=====================\")\n",
    "# print(test_data)\n",
    "\n",
    "for i, (images, labels) in enumerate(train_loader):\n",
    "    print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[1]\n",
      "torch.Size([1, 28, 28])\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#visualising the size of the image and its labels\n",
    "for image , label in train_data:\n",
    "    print(image.shape)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying images on Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location of tensorboard folder\n",
    "folder=\"runs/DisplayImage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: runs/DisplayImage\\events.out.tfevents.1733367504.DESKTOP-3FC1MTH.2956.7\n",
      "All contents of the folder 'runs/DisplayImage' have been cleared.\n"
     ]
    }
   ],
   "source": [
    "clear_folder(folder)\n",
    "#show using dataset on tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\n",
    "writer = SummaryWriter(f\"runs/DisplayImage\")\n",
    "for index in range(100):\n",
    "    data,label=train_data[index]\n",
    "    writer.add_image(\"mnist_images\", data,index)\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: runs/DisplayImage\\events.out.tfevents.1733693393.DESKTOP-3FC1MTH.31004.0\n",
      "All contents of the folder 'runs/DisplayImage' have been cleared.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method SummaryWriter.close of <torch.utils.tensorboard.writer.SummaryWriter object at 0x00000239C7E63A60>>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_folder(folder)\n",
    "#show using dataloader with batches\n",
    "for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "    # create grid of images\n",
    "    img_grid = torchvision.utils.make_grid(data)\n",
    "    # write to tensorboard\n",
    "    writer.add_image(f\"MNIST Example - image batch \", img_grid,batch_idx)\n",
    "    #print(batch_idx)\n",
    "writer.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img,label = train_data[1]\n",
    "image_np = img.squeeze()\n",
    "print(image_np.shape)\n",
    "# Plot the image\n",
    "plt.imshow(image_np,cmap=\"gray\")\n",
    "plt.axis('off')  # Hide the axes for better visualization\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully connected network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1650'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device cuda for GPU if it's available otherwise run on the CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to build model and forward path of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        \"\"\"\n",
    "        Here we define the layers of the network. We create two fully connected layers\n",
    "\n",
    "        Parameters:\n",
    "            input_size: the size of the input, in this case 784 (28x28)\n",
    "            num_classes: the number of classes we want to predict, in this case 2 (0-1)\n",
    "\n",
    "        \"\"\"\n",
    "        super(NN, self).__init__()\n",
    "        # # Our first linear layer take input_size, in this case 784 nodes to 50\n",
    "        # # and our second linear layer takes 50 to the num_classes we have, in\n",
    "        # # this case 10.\n",
    "        # self.fc1 = nn.Linear(input_size, 50)\n",
    "        # self.fc2 = nn.Linear(50, num_classes)\n",
    "\n",
    "        self.flatten = nn.Flatten() #flattens the input tensors\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x here is the mnist images and we run it through the network that we created above.\n",
    "        Parameters:\n",
    "            x: mnist images\n",
    "        Returns:\n",
    "            out: the output of the network\n",
    "        \"\"\"\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Deleted: runs/DisplayImage\\events.out.tfevents.1733693471.DESKTOP-3FC1MTH.31004.1\n",
      "All contents of the folder 'runs/DisplayImage' have been cleared.\n",
      "Model sent to tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "input_size = 28*28\n",
    "num_classes = 2\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 15\n",
    "\n",
    "model = NN(input_size=input_size, num_classes=num_classes).to(device)\n",
    "print(model)\n",
    "\n",
    "clear_folder(folder)\n",
    "# Visualize model in TensorBoard\n",
    "example_img, labels = next(iter(train_loader))\n",
    "#example_img=example_img[0]\n",
    "writer.add_graph(model,example_img.to(device))\n",
    "print(\"Model sent to tensorboard\")\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (input_data, class_cat) in enumerate(tqdm(dataloader)):\n",
    "        input_data, class_cat = input_data.to(device), class_cat.to(device)\n",
    "\n",
    "        # Compute prediction error)\n",
    "        pred = model(input_data)\n",
    "        class_cat=class_cat.squeeze().long()\n",
    "        loss = loss_fn(pred, class_cat)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "  \n",
    "\n",
    "        loss, current = loss.item(), (batch + 1) * len(input_data)\n",
    "        print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y=y.squeeze().long()\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_cat shape: torch.Size([20])\n",
      "class_cat values: tensor([0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0],\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "data,label=next(iter(train_loader))\n",
    "#print(label)\n",
    "label=label.squeeze()\n",
    "print(f\"class_cat shape: {label.shape}\")\n",
    "print(f\"class_cat values: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 9/28 [00:00<00:00, 81.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.505002  [   20/  546]\n",
      "loss: 0.486172  [   40/  546]\n",
      "loss: 0.576357  [   60/  546]\n",
      "loss: 0.267544  [   80/  546]\n",
      "loss: 0.427599  [  100/  546]\n",
      "loss: 0.394226  [  120/  546]\n",
      "loss: 0.607681  [  140/  546]\n",
      "loss: 0.337550  [  160/  546]\n",
      "loss: 0.213325  [  180/  546]\n",
      "loss: 0.426159  [  200/  546]\n",
      "loss: 0.501041  [  220/  546]\n",
      "loss: 0.466900  [  240/  546]\n",
      "loss: 0.427361  [  260/  546]\n",
      "loss: 0.340910  [  280/  546]\n",
      "loss: 0.527612  [  300/  546]\n",
      "loss: 0.544178  [  320/  546]\n",
      "loss: 0.219218  [  340/  546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 81.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.330507  [  360/  546]\n",
      "loss: 0.283904  [  380/  546]\n",
      "loss: 0.418451  [  400/  546]\n",
      "loss: 0.353409  [  420/  546]\n",
      "loss: 0.413486  [  440/  546]\n",
      "loss: 0.563025  [  460/  546]\n",
      "loss: 0.338526  [  480/  546]\n",
      "loss: 0.623747  [  500/  546]\n",
      "loss: 0.392919  [  520/  546]\n",
      "loss: 0.294143  [  540/  546]\n",
      "loss: 0.293040  [  168/  546]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.466436 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.319938  [   20/  546]\n",
      "loss: 0.551069  [   40/  546]\n",
      "loss: 0.383456  [   60/  546]\n",
      "loss: 0.401815  [   80/  546]\n",
      "loss: 0.490476  [  100/  546]\n",
      "loss: 0.484383  [  120/  546]\n",
      "loss: 0.425047  [  140/  546]\n",
      "loss: 0.155335  [  160/  546]\n",
      "loss: 0.346275  [  180/  546]\n",
      "loss: 0.397289  [  200/  546]\n",
      "loss: 0.172861  [  220/  546]\n",
      "loss: 0.234420  [  240/  546]\n",
      "loss: 0.402672  [  260/  546]\n",
      "loss: 0.536435  [  280/  546]\n",
      "loss: 0.376136  [  300/  546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 251.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.682158  [  320/  546]\n",
      "loss: 0.259155  [  340/  546]\n",
      "loss: 0.599857  [  360/  546]\n",
      "loss: 0.365980  [  380/  546]\n",
      "loss: 0.458779  [  400/  546]\n",
      "loss: 0.578183  [  420/  546]\n",
      "loss: 0.320381  [  440/  546]\n",
      "loss: 0.486362  [  460/  546]\n",
      "loss: 0.276440  [  480/  546]\n",
      "loss: 0.392074  [  500/  546]\n",
      "loss: 0.407759  [  520/  546]\n",
      "loss: 0.287012  [  540/  546]\n",
      "loss: 0.143399  [  168/  546]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.541854 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.538655  [   20/  546]\n",
      "loss: 0.428748  [   40/  546]\n",
      "loss: 0.511143  [   60/  546]\n",
      "loss: 0.365423  [   80/  546]\n",
      "loss: 0.662430  [  100/  546]\n",
      "loss: 0.428741  [  120/  546]\n",
      "loss: 0.527729  [  140/  546]\n",
      "loss: 0.520898  [  160/  546]\n",
      "loss: 0.385874  [  180/  546]\n",
      "loss: 0.386274  [  200/  546]\n",
      "loss: 0.308713  [  220/  546]\n",
      "loss: 0.368877  [  240/  546]\n",
      "loss: 0.426836  [  260/  546]\n",
      "loss: 0.501583  [  280/  546]\n",
      "loss: 0.310708  [  300/  546]\n",
      "loss: 0.279476  [  320/  546]\n",
      "loss: 0.505690  [  340/  546]\n",
      "loss: 0.284520  [  360/  546]\n",
      "loss: 0.441393  [  380/  546]\n",
      "loss: 0.546893  [  400/  546]\n",
      "loss: 0.364456  [  420/  546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 242.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.334943  [  440/  546]\n",
      "loss: 0.322749  [  460/  546]\n",
      "loss: 0.431044  [  480/  546]\n",
      "loss: 0.249560  [  500/  546]\n",
      "loss: 0.331483  [  520/  546]\n",
      "loss: 0.400657  [  540/  546]\n",
      "loss: 0.110487  [  168/  546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.570040 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.511780  [   20/  546]\n",
      "loss: 0.418662  [   40/  546]\n",
      "loss: 0.162522  [   60/  546]\n",
      "loss: 0.457968  [   80/  546]\n",
      "loss: 0.296209  [  100/  546]\n",
      "loss: 0.453399  [  120/  546]\n",
      "loss: 0.216080  [  140/  546]\n",
      "loss: 0.322213  [  160/  546]\n",
      "loss: 0.473736  [  180/  546]\n",
      "loss: 0.394929  [  200/  546]\n",
      "loss: 0.170309  [  220/  546]\n",
      "loss: 0.494114  [  240/  546]\n",
      "loss: 0.410244  [  260/  546]\n",
      "loss: 0.558473  [  280/  546]\n",
      "loss: 0.240073  [  300/  546]\n",
      "loss: 0.268685  [  320/  546]\n",
      "loss: 0.475268  [  340/  546]\n",
      "loss: 0.405234  [  360/  546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 237.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.328379  [  380/  546]\n",
      "loss: 0.322802  [  400/  546]\n",
      "loss: 0.384297  [  420/  546]\n",
      "loss: 0.599348  [  440/  546]\n",
      "loss: 0.314612  [  460/  546]\n",
      "loss: 0.484185  [  480/  546]\n",
      "loss: 0.267710  [  500/  546]\n",
      "loss: 0.392013  [  520/  546]\n",
      "loss: 0.405579  [  540/  546]\n",
      "loss: 0.753774  [  168/  546]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.506959 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.498051  [   20/  546]\n",
      "loss: 0.270889  [   40/  546]\n",
      "loss: 0.513591  [   60/  546]\n",
      "loss: 0.516545  [   80/  546]\n",
      "loss: 0.422079  [  100/  546]\n",
      "loss: 0.557128  [  120/  546]\n",
      "loss: 0.282786  [  140/  546]\n",
      "loss: 0.425682  [  160/  546]\n",
      "loss: 0.476935  [  180/  546]\n",
      "loss: 0.352237  [  200/  546]\n",
      "loss: 0.396685  [  220/  546]\n",
      "loss: 0.450901  [  240/  546]\n",
      "loss: 0.396674  [  260/  546]\n",
      "loss: 0.297881  [  280/  546]\n",
      "loss: 0.254003  [  300/  546]\n",
      "loss: 0.436910  [  320/  546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 21/28 [00:00<00:00, 208.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.229422  [  340/  546]\n",
      "loss: 0.366818  [  360/  546]\n",
      "loss: 0.352043  [  380/  546]\n",
      "loss: 0.160525  [  400/  546]\n",
      "loss: 0.304501  [  420/  546]\n",
      "loss: 0.336082  [  440/  546]\n",
      "loss: 0.488340  [  460/  546]\n",
      "loss: 0.404189  [  480/  546]\n",
      "loss: 0.581077  [  500/  546]\n",
      "loss: 0.543742  [  520/  546]\n",
      "loss: 0.641605  [  540/  546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 208.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.566260  [  168/  546]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.501898 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.252378  [   20/  546]\n",
      "loss: 0.502695  [   40/  546]\n",
      "loss: 0.472305  [   60/  546]\n",
      "loss: 0.532778  [   80/  546]\n",
      "loss: 0.371111  [  100/  546]\n",
      "loss: 0.229282  [  120/  546]\n",
      "loss: 0.330731  [  140/  546]\n",
      "loss: 0.291380  [  160/  546]\n",
      "loss: 0.361399  [  180/  546]\n",
      "loss: 0.283880  [  200/  546]\n",
      "loss: 0.449722  [  220/  546]\n",
      "loss: 0.494056  [  240/  546]\n",
      "loss: 0.458777  [  260/  546]\n",
      "loss: 0.463912  [  280/  546]\n",
      "loss: 0.549155  [  300/  546]\n",
      "loss: 0.418233  [  320/  546]\n",
      "loss: 0.366010  [  340/  546]\n",
      "loss: 0.370277  [  360/  546]\n",
      "loss: 0.365275  [  380/  546]\n",
      "loss: 0.304460  [  400/  546]\n",
      "loss: 0.400317  [  420/  546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 226.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.318578  [  440/  546]\n",
      "loss: 0.234351  [  460/  546]\n",
      "loss: 0.335049  [  480/  546]\n",
      "loss: 0.754313  [  500/  546]\n",
      "loss: 0.134493  [  520/  546]\n",
      "loss: 0.364856  [  540/  546]\n",
      "loss: 0.099094  [  168/  546]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.492853 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.268847  [   20/  546]\n",
      "loss: 0.512243  [   40/  546]\n",
      "loss: 0.406511  [   60/  546]\n",
      "loss: 0.442337  [   80/  546]\n",
      "loss: 0.331417  [  100/  546]\n",
      "loss: 0.287629  [  120/  546]\n",
      "loss: 0.240190  [  140/  546]\n",
      "loss: 0.351271  [  160/  546]\n",
      "loss: 0.206409  [  180/  546]\n",
      "loss: 0.296557  [  200/  546]\n",
      "loss: 0.331192  [  220/  546]\n",
      "loss: 0.462343  [  240/  546]\n",
      "loss: 0.637507  [  260/  546]\n",
      "loss: 0.371628  [  280/  546]\n",
      "loss: 0.221581  [  300/  546]\n",
      "loss: 0.416704  [  320/  546]\n",
      "loss: 1.050036  [  340/  546]\n",
      "loss: 0.275495  [  360/  546]\n",
      "loss: 0.353338  [  380/  546]\n",
      "loss: 0.117679  [  400/  546]\n",
      "loss: 0.472097  [  420/  546]\n",
      "loss: 0.497030  [  440/  546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 244.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.185906  [  460/  546]\n",
      "loss: 0.577022  [  480/  546]\n",
      "loss: 0.694717  [  500/  546]\n",
      "loss: 0.613316  [  520/  546]\n",
      "loss: 0.487334  [  540/  546]\n",
      "loss: 0.363579  [  168/  546]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.491861 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.256727  [   20/  546]\n",
      "loss: 0.310086  [   40/  546]\n",
      "loss: 0.281093  [   60/  546]\n",
      "loss: 0.557680  [   80/  546]\n",
      "loss: 0.438085  [  100/  546]\n",
      "loss: 0.489762  [  120/  546]\n",
      "loss: 0.432690  [  140/  546]\n",
      "loss: 0.380137  [  160/  546]\n",
      "loss: 0.561269  [  180/  546]\n",
      "loss: 0.316659  [  200/  546]\n",
      "loss: 0.457723  [  220/  546]\n",
      "loss: 0.461764  [  240/  546]\n",
      "loss: 0.427600  [  260/  546]\n",
      "loss: 0.382569  [  280/  546]\n",
      "loss: 0.585852  [  300/  546]\n",
      "loss: 0.429583  [  320/  546]\n",
      "loss: 0.313293  [  340/  546]\n",
      "loss: 0.588147  [  360/  546]\n",
      "loss: 0.403606  [  380/  546]\n",
      "loss: 0.293709  [  400/  546]\n",
      "loss: 0.258962  [  420/  546]\n",
      "loss: 0.609561  [  440/  546]\n",
      "loss: 0.268136  [  460/  546]\n",
      "loss: 0.476158  [  480/  546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 246.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.389111  [  500/  546]\n",
      "loss: 0.254903  [  520/  546]\n",
      "loss: 0.442951  [  540/  546]\n",
      "loss: 0.092775  [  168/  546]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.476020 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.253342  [   20/  546]\n",
      "loss: 0.281644  [   40/  546]\n",
      "loss: 0.498310  [   60/  546]\n",
      "loss: 0.387129  [   80/  546]\n",
      "loss: 0.603267  [  100/  546]\n",
      "loss: 0.363649  [  120/  546]\n",
      "loss: 0.397055  [  140/  546]\n",
      "loss: 0.264572  [  160/  546]\n",
      "loss: 0.275593  [  180/  546]\n",
      "loss: 0.249582  [  200/  546]\n",
      "loss: 0.324396  [  220/  546]\n",
      "loss: 0.339117  [  240/  546]\n",
      "loss: 0.382870  [  260/  546]\n",
      "loss: 0.116713  [  280/  546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 25/28 [00:00<00:00, 237.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.252368  [  300/  546]\n",
      "loss: 0.355690  [  320/  546]\n",
      "loss: 0.453088  [  340/  546]\n",
      "loss: 0.703589  [  360/  546]\n",
      "loss: 0.570823  [  380/  546]\n",
      "loss: 0.444249  [  400/  546]\n",
      "loss: 0.306501  [  420/  546]\n",
      "loss: 0.464153  [  440/  546]\n",
      "loss: 0.484670  [  460/  546]\n",
      "loss: 0.408134  [  480/  546]\n",
      "loss: 0.359313  [  500/  546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 236.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.416766  [  520/  546]\n",
      "loss: 0.419912  [  540/  546]\n",
      "loss: 0.360043  [  168/  546]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.588287 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.378019  [   20/  546]\n",
      "loss: 0.395371  [   40/  546]\n",
      "loss: 0.482962  [   60/  546]\n",
      "loss: 0.183230  [   80/  546]\n",
      "loss: 0.293818  [  100/  546]\n",
      "loss: 0.411094  [  120/  546]\n",
      "loss: 0.575463  [  140/  546]\n",
      "loss: 0.249878  [  160/  546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 23/28 [00:00<00:00, 223.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.518891  [  180/  546]\n",
      "loss: 0.357158  [  200/  546]\n",
      "loss: 0.472495  [  220/  546]\n",
      "loss: 0.359753  [  240/  546]\n",
      "loss: 0.409485  [  260/  546]\n",
      "loss: 0.432833  [  280/  546]\n",
      "loss: 0.411670  [  300/  546]\n",
      "loss: 0.349428  [  320/  546]\n",
      "loss: 0.279307  [  340/  546]\n",
      "loss: 0.469297  [  360/  546]\n",
      "loss: 0.398713  [  380/  546]\n",
      "loss: 0.339803  [  400/  546]\n",
      "loss: 0.572137  [  420/  546]\n",
      "loss: 0.285799  [  440/  546]\n",
      "loss: 0.224625  [  460/  546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 238.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.335028  [  480/  546]\n",
      "loss: 0.353221  [  500/  546]\n",
      "loss: 0.343801  [  520/  546]\n",
      "loss: 0.406028  [  540/  546]\n",
      "loss: 0.300115  [  168/  546]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.514453 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.331317  [   20/  546]\n",
      "loss: 0.182863  [   40/  546]\n",
      "loss: 0.291294  [   60/  546]\n",
      "loss: 0.303914  [   80/  546]\n",
      "loss: 0.288874  [  100/  546]\n",
      "loss: 0.488774  [  120/  546]\n",
      "loss: 0.317209  [  140/  546]\n",
      "loss: 0.246380  [  160/  546]\n",
      "loss: 0.301287  [  180/  546]\n",
      "loss: 0.314435  [  200/  546]\n",
      "loss: 0.304689  [  220/  546]\n",
      "loss: 0.736331  [  240/  546]\n",
      "loss: 0.330934  [  260/  546]\n",
      "loss: 0.148248  [  280/  546]\n",
      "loss: 0.382713  [  300/  546]\n",
      "loss: 0.340946  [  320/  546]\n",
      "loss: 0.416976  [  340/  546]\n",
      "loss: 0.343758  [  360/  546]\n",
      "loss: 0.305925  [  380/  546]\n",
      "loss: 0.459449  [  400/  546]\n",
      "loss: 0.226405  [  420/  546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 223.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.179993  [  440/  546]\n",
      "loss: 0.479727  [  460/  546]\n",
      "loss: 0.445100  [  480/  546]\n",
      "loss: 0.683332  [  500/  546]\n",
      "loss: 0.375961  [  520/  546]\n",
      "loss: 0.395109  [  540/  546]\n",
      "loss: 0.422283  [  168/  546]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.458947 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.327650  [   20/  546]\n",
      "loss: 0.755067  [   40/  546]\n",
      "loss: 0.346280  [   60/  546]\n",
      "loss: 0.313094  [   80/  546]\n",
      "loss: 0.314352  [  100/  546]\n",
      "loss: 0.555950  [  120/  546]\n",
      "loss: 0.635198  [  140/  546]\n",
      "loss: 0.584467  [  160/  546]\n",
      "loss: 0.313688  [  180/  546]\n",
      "loss: 0.518447  [  200/  546]\n",
      "loss: 0.323383  [  220/  546]\n",
      "loss: 0.386548  [  240/  546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 24/28 [00:00<00:00, 232.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.303362  [  260/  546]\n",
      "loss: 0.417294  [  280/  546]\n",
      "loss: 0.289253  [  300/  546]\n",
      "loss: 0.353553  [  320/  546]\n",
      "loss: 0.517391  [  340/  546]\n",
      "loss: 0.376792  [  360/  546]\n",
      "loss: 0.397359  [  380/  546]\n",
      "loss: 0.294886  [  400/  546]\n",
      "loss: 0.535989  [  420/  546]\n",
      "loss: 0.263275  [  440/  546]\n",
      "loss: 0.248476  [  460/  546]\n",
      "loss: 0.234551  [  480/  546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 245.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.192485  [  500/  546]\n",
      "loss: 0.342716  [  520/  546]\n",
      "loss: 0.299851  [  540/  546]\n",
      "loss: 0.208266  [  168/  546]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.477514 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.376082  [   20/  546]\n",
      "loss: 0.112606  [   40/  546]\n",
      "loss: 0.535637  [   60/  546]\n",
      "loss: 0.307663  [   80/  546]\n",
      "loss: 0.252638  [  100/  546]\n",
      "loss: 0.281132  [  120/  546]\n",
      "loss: 0.269241  [  140/  546]\n",
      "loss: 0.543180  [  160/  546]\n",
      "loss: 0.605354  [  180/  546]\n",
      "loss: 0.389215  [  200/  546]\n",
      "loss: 0.435129  [  220/  546]\n",
      "loss: 0.215953  [  240/  546]\n",
      "loss: 0.232263  [  260/  546]\n",
      "loss: 0.200445  [  280/  546]\n",
      "loss: 0.241361  [  300/  546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 22/28 [00:00<00:00, 218.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.370582  [  320/  546]\n",
      "loss: 0.265620  [  340/  546]\n",
      "loss: 0.213743  [  360/  546]\n",
      "loss: 0.188492  [  380/  546]\n",
      "loss: 0.419848  [  400/  546]\n",
      "loss: 0.573751  [  420/  546]\n",
      "loss: 0.224305  [  440/  546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 212.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.376841  [  460/  546]\n",
      "loss: 0.203439  [  480/  546]\n",
      "loss: 0.610090  [  500/  546]\n",
      "loss: 0.463813  [  520/  546]\n",
      "loss: 0.389353  [  540/  546]\n",
      "loss: 0.318456  [  168/  546]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.473626 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.311909  [   20/  546]\n",
      "loss: 0.302187  [   40/  546]\n",
      "loss: 0.267523  [   60/  546]\n",
      "loss: 0.345180  [   80/  546]\n",
      "loss: 0.281927  [  100/  546]\n",
      "loss: 0.348600  [  120/  546]\n",
      "loss: 0.407661  [  140/  546]\n",
      "loss: 0.279864  [  160/  546]\n",
      "loss: 0.240962  [  180/  546]\n",
      "loss: 0.350628  [  200/  546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 21/28 [00:00<00:00, 203.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.213136  [  220/  546]\n",
      "loss: 0.287188  [  240/  546]\n",
      "loss: 0.305406  [  260/  546]\n",
      "loss: 0.252894  [  280/  546]\n",
      "loss: 0.389646  [  300/  546]\n",
      "loss: 0.414522  [  320/  546]\n",
      "loss: 0.354316  [  340/  546]\n",
      "loss: 0.506348  [  360/  546]\n",
      "loss: 0.289406  [  380/  546]\n",
      "loss: 0.260893  [  400/  546]\n",
      "loss: 0.466033  [  420/  546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 212.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.224825  [  440/  546]\n",
      "loss: 0.476213  [  460/  546]\n",
      "loss: 0.413002  [  480/  546]\n",
      "loss: 0.636224  [  500/  546]\n",
      "loss: 0.417231  [  520/  546]\n",
      "loss: 0.380930  [  540/  546]\n",
      "loss: 0.497089  [  168/  546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.531968 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.316234  [   20/  546]\n",
      "loss: 0.191005  [   40/  546]\n",
      "loss: 0.480057  [   60/  546]\n",
      "loss: 0.319383  [   80/  546]\n",
      "loss: 0.248109  [  100/  546]\n",
      "loss: 0.568281  [  120/  546]\n",
      "loss: 0.392455  [  140/  546]\n",
      "loss: 0.259132  [  160/  546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 20/28 [00:00<00:00, 198.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.397623  [  180/  546]\n",
      "loss: 0.491086  [  200/  546]\n",
      "loss: 0.417659  [  220/  546]\n",
      "loss: 0.311957  [  240/  546]\n",
      "loss: 0.329686  [  260/  546]\n",
      "loss: 0.104090  [  280/  546]\n",
      "loss: 0.230424  [  300/  546]\n",
      "loss: 0.522868  [  320/  546]\n",
      "loss: 0.597433  [  340/  546]\n",
      "loss: 0.228753  [  360/  546]\n",
      "loss: 0.179422  [  380/  546]\n",
      "loss: 0.387163  [  400/  546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 206.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.517322  [  420/  546]\n",
      "loss: 0.404912  [  440/  546]\n",
      "loss: 0.277396  [  460/  546]\n",
      "loss: 0.359367  [  480/  546]\n",
      "loss: 0.351558  [  500/  546]\n",
      "loss: 0.590605  [  520/  546]\n",
      "loss: 0.128133  [  540/  546]\n",
      "loss: 0.352110  [  168/  546]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.536645 \n",
      "\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for t in range(num_epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    test(test_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example from YT of creating new neural network and training it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:07<00:00, 117.40it/s]\n",
      "100%|██████████| 938/938 [00:08<00:00, 116.94it/s]\n",
      "100%|██████████| 938/938 [00:07<00:00, 118.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 96.31\n",
      "Accuracy on test set: 95.92\n",
      "time=23.94032645225525\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "A simple walkthrough of how to code a fully connected neural network\n",
    "using the PyTorch library. For demonstration we train it on the very\n",
    "common MNIST dataset of handwritten digits. In this code we go through\n",
    "how to create the network as well as initialize a loss function, optimizer,\n",
    "check accuracy and more.\n",
    "\n",
    "Programmed by Aladdin Persson\n",
    "* 2020-04-08: Initial coding\n",
    "* 2021-03-24: Added more detailed comments also removed part of\n",
    "              check_accuracy which would only work specifically on MNIST.\n",
    "* 2022-09-23: Updated with more detailed comments, docstrings to functions, and checked code still functions as intended.\n",
    "\"\"\"\n",
    "\n",
    "# Imports\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
    "import torchvision.datasets as datasets  # Standard datasets\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
    "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
    "from torch import nn  # All neural network modules\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    ")  # Gives easier dataset managment by creating mini batches etc.\n",
    "from tqdm import tqdm  # For nice progress bar!\n",
    "\n",
    "# Here we create our simple neural network. For more details here we are subclassing and\n",
    "# inheriting from nn.Module, this is the most general way to create your networks and\n",
    "# allows for more flexibility. I encourage you to also check out nn.Sequential which\n",
    "# would be easier to use in this scenario but I wanted to show you something that\n",
    "# \"always\" works and is a general approach.\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        \"\"\"\n",
    "        Here we define the layers of the network. We create two fully connected layers\n",
    "\n",
    "        Parameters:\n",
    "            input_size: the size of the input, in this case 784 (28x28)\n",
    "            num_classes: the number of classes we want to predict, in this case 10 (0-9)\n",
    "\n",
    "        \"\"\"\n",
    "        super(NN, self).__init__()\n",
    "        # Our first linear layer take input_size, in this case 784 nodes to 50\n",
    "        # and our second linear layer takes 50 to the num_classes we have, in\n",
    "        # this case 10.\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x here is the mnist images and we run it through fc1, fc2 that we created above.\n",
    "        we also add a ReLU activation function in between and for that (since it has no parameters)\n",
    "        I recommend using nn.functional (F)\n",
    "\n",
    "        Parameters:\n",
    "            x: mnist images\n",
    "\n",
    "        Returns:\n",
    "            out: the output of the network\n",
    "        \"\"\"\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Set device cuda for GPU if it's available otherwise run on the CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "torch.cuda.get_device_name(0)\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 784\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 3\n",
    "\n",
    "# Load Data\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize network\n",
    "model = NN(input_size=input_size, num_classes=num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "start=time.time()\n",
    "# Train Network\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
    "        # Get data to cuda if possible\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        # print(\"before\")\n",
    "        # print(data.shape)\n",
    "        # Get to correct shape\n",
    "        data = data.reshape(data.shape[0], -1)\n",
    "        # print(\"after\")\n",
    "        # print(data.shape)\n",
    "        # Forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient descent or adam step\n",
    "        optimizer.step()\n",
    "end=time.time()\n",
    "\n",
    "# Check accuracy on training & test to see how good our model\n",
    "def check_accuracy(loader, model):\n",
    "    \"\"\"\n",
    "    Check accuracy of our trained model given a loader and a model\n",
    "\n",
    "    Parameters:\n",
    "        loader: torch.utils.data.DataLoader\n",
    "            A loader for the dataset you want to check accuracy on\n",
    "        model: nn.Module\n",
    "            The model you want to check accuracy on\n",
    "\n",
    "    Returns:\n",
    "        acc: float\n",
    "            The accuracy of the model on the dataset given by the loader\n",
    "    \"\"\"\n",
    "\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    # We don't need to keep track of gradients here so we wrap it in torch.no_grad()\n",
    "    with torch.no_grad():\n",
    "        # Loop through the data\n",
    "        for x, y in loader:\n",
    "\n",
    "            # Move data to device\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            # Get to correct shape\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "            # Forward pass\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "\n",
    "            # Check how many we got correct\n",
    "            num_correct += (predictions == y).sum()\n",
    "\n",
    "            # Keep track of number of samples\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "    model.train()\n",
    "    return num_correct / num_samples\n",
    "\n",
    "\n",
    "# Check accuracy on training & test to see how good our model\n",
    "print(f\"Accuracy on training set: {check_accuracy(train_loader, model)*100:.2f}\")\n",
    "print(f\"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}\")\n",
    "duration=end-start\n",
    "print(f\"time={duration}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLS_CW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
